{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to EvoXBench\n",
    "\n",
    "In this notebook, we will demonstrate \n",
    "- how to install EvoXBench\n",
    "- the basics of EvoXBench\n",
    "\n",
    "**[EvoXBench](https://arxiv.org/abs/2208.04321)** is an efficient platform \n",
    "for facilitating neural architecture search (NAS) \n",
    "without the requirement of *GPUs* or \n",
    "sophisticated deep learning packages, such as *PyTorch, TensorFlow*, etc.\n",
    "\n",
    "![](https://raw.githubusercontent.com/EMI-Group/evoxbench/main/assets/evoxbench_overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation \n",
    "Let's perform the following steps to have EvoXBench properly installed. \n",
    "\n",
    "First, download the following two files:\n",
    "- ``database_xxx.zip`` from [Google Drive](https://drive.google.com/file/d/11bQ1paHEWHDnnTPtxs2OyVY_Re-38DiO/view?usp=sharing) or [Baidu NetDisk](https://pan.baidu.com/s/1PwWloA543-81O-GFkA7GKg)\n",
    "- ``data_xxx.zip`` from [Google Drive](https://drive.google.com/file/d/1fUZtpTjfEQao2unLKaspL8fOq4xdSXt2/view?usp=sharing) or [Baidu NetDisk](https://pan.baidu.com/s/1yopkISKyjbWIHXFV_Op3pg)\n",
    "\n",
    "Second, unzip these two files and find their paths\n",
    "- my ``database`` and ``data`` are unzipped to:\n",
    "```python\n",
    "    # /Users/luzhicha/Dropbox/2023/github/evoxbench/\n",
    "    # └─ database/\n",
    "    # |  |  __init__.py\n",
    "    # |  |  db.sqlite3\n",
    "    # |  |  ...\n",
    "    # |  \n",
    "    # └─ data/\n",
    "    #    └─ darts/\n",
    "    #    └─ mnv3/\n",
    "    #    └─ ...\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurating EvoXBench...\n",
      "Auto Configuration Succeed!, Using database /opt/data/private/BigFiles/EvoXBench_tutorial_materials_IEEE CEC’2023 Competition on Multiobjective Neural Architecture Search/database.\n",
      "Configuration Succeed!\n"
     ]
    }
   ],
   "source": [
    "print('Configurating EvoXBench...')\n",
    "from evoxbench.database.init import config\n",
    "# make sure you update these two paths accordingly, and the first path should be for database file\n",
    "config(\"/opt/data/private/BigFiles/EvoXBench_tutorial_materials_IEEE CEC’2023 Competition on Multiobjective Neural Architecture Search/database\",\n",
    "       \"/opt/data/private/BigFiles/EvoXBench_tutorial_materials_IEEE CEC’2023 Competition on Multiobjective Neural Architecture Search/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good! Now we have successfully installed and configured **EvoXBench**. Let's now get started with some quick examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 How to create a NAS benchmark (search space)\n",
    "\n",
    "**EvoXBench** currently supports the following seven search spaces\n",
    "\n",
    "| $\\Omega$ | $D$ | $|\\Omega|$ | Objectives | Dataset |\n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "| [NB101](https://github.com/google-research/nasbench) | 26 |423K | $f^{e}$, ${f}^{c}$ | CIFAR-10 |\n",
    "| [NB201](https://github.com/D-X-Y/NAS-Bench-201) | 6 | 15.6K | $f^{e}$, ${f}^{c}$, ${f}^{\\mathcal{H}}$ | CIFAR-10 |\n",
    "| [NATS](https://github.com/D-X-Y/NATS-Bench) | 5 | 32.8K | $f^{e}$, ${f}^{c}$, ${f}^{\\mathcal{H}}$ | CIFAR-10 |\n",
    "| [DARTS](https://github.com/automl/nasbench301) | 32 | $\\sim10^{21}$ | $f^{e}$, ${f}^{c}$ | CIFAR-10 |\n",
    "| [ResNet-50](https://github.com/mit-han-lab/once-for-all) | 25 | $\\sim10^{14}$ | $f^{e}$, ${f}^{c}$ | ImageNet-1K |\n",
    "| [Transformer](https://github.com/microsoft/Cream/tree/main/AutoFormer) | 34 | $\\sim10^{14}$ | $f^{e}$, ${f}^{c}$ | ImageNet-1K |\n",
    "| [MNV3](https://github.com/mit-han-lab/once-for-all) | 21 | $\\sim10^{20}$ | $f^{e}$, ${f}^{c}$, ${f}^{\\mathcal{H}}$ | ImageNet-1K |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto Configuration Succeed!, Using database J:\\BigFiles\\EvoXBench_tutorial_materials_IEEE CEC’2023 Competition on Multiobjective Neural Architecture Search\\database20220713\\database.\n",
      "Benchmaking on NB101 search space with objectives: err&params&flops\n"
     ]
    }
   ],
   "source": [
    "# NAS-Bench-101 search space\n",
    "from evoxbench.benchmarks import NASBench101Benchmark\n",
    "objs = 'err&params&flops'  # ['err&params', 'err&flops', 'err&params&flops']\n",
    "benchmark = NASBench101Benchmark(objs=objs, normalized_objectives=False)\n",
    "print(\"Benchmaking on NB101 search space with objectives: {}\".format(objs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 How to evaluate an architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly create 1 architectures:\n",
      "[{'matrix': array([[0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 1, 0, 1],\n",
      "       [0, 0, 0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0]]), 'ops': ['input', 'conv1x1-bn-relu', 'maxpool3x3', 'conv3x3-bn-relu', 'conv3x3-bn-relu', 'conv3x3-bn-relu', 'output']}]\n"
     ]
    }
   ],
   "source": [
    "# let's randomly create N architectures\n",
    "N = 1\n",
    "archs = benchmark.search_space.sample(N)\n",
    "print('Randomly create {} architectures:'.format(N))\n",
    "print(archs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode architectures to decision variables X: \n",
      "[[0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 1 2 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# encode architecture (phenotype) to decision variables (genotypes)\n",
    "X = benchmark.search_space.encode(archs)\n",
    "print('Encode architectures to decision variables X: ')\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating architectures for objectives: err&params&flops\n",
      "[[ 1. inf inf]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the objective values\n",
    "# if true_eval is True, return mean TEST accuracy over multiple runs, \n",
    "# should only be used for final comparison.\n",
    "true_eval = True\n",
    "F = benchmark.evaluate(X, true_eval=true_eval)\n",
    "print(\"Evaluating architectures for objectives: {}\".format(objs))\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating architectures for objectives: err&params\n",
      "Trial 1:\n",
      "[[5.86938858e-02 4.34215400e+06]]\n",
      "Trial 2:\n",
      "[[6.14984035e-02 4.34215400e+06]]\n",
      "Trial 3:\n",
      "[[6.3100934e-02 4.3421540e+06]]\n",
      "Trial 4:\n",
      "[[6.3100934e-02 4.3421540e+06]]\n",
      "Trial 5:\n",
      "[[6.3100934e-02 4.3421540e+06]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the objective values\n",
    "# if true_eval is False, return VALIDATION accuracy from one (randomly selected) run, \n",
    "# should be used during search\n",
    "true_eval = False\n",
    "print(\"Evaluating architectures for objectives: {}\".format(objs))\n",
    "for i in range(5):\n",
    "    F = benchmark.evaluate(X, true_eval=true_eval)\n",
    "    print(\"Trial {}:\".format(i+1))\n",
    "    print(F)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Other benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmaking on NB201 search space with objectives: err&params&flops&edgegpu_latency&edgegpu_energy\n",
      "['|avg_pool_3x3~0|+|none~0|nor_conv_3x3~1|+|nor_conv_3x3~0|nor_conv_1x1~1|avg_pool_3x3~2|']\n",
      "[[4 0 3 3 2 4]]\n",
      "[[ 8.40333333  0.587386   82.49409     6.83680534 31.76607656]]\n"
     ]
    }
   ],
   "source": [
    "# NAS-Bench-201 search space\n",
    "from evoxbench.benchmarks import NASBench201Benchmark\n",
    "# hardware = 'edgegpu'  # ['edgegpu', 'raspi4', 'edgetpu', 'pixel3', 'eyeriss', 'fpga']\n",
    "# ['err&params', 'err&flops', 'err&latency', 'err&params&flops', 'err&params&latency', ...]\n",
    "objs = 'err&params&flops&edgegpu_latency&edgegpu_energy'\n",
    "benchmark = NASBench201Benchmark(objs=objs, normalized_objectives=False)\n",
    "print(\"Benchmaking on NB201 search space with objectives: {}\".format(objs))\n",
    "archs = benchmark.search_space.sample(1)\n",
    "print(archs)\n",
    "X = benchmark.search_space.encode(archs)\n",
    "print(X)\n",
    "F = benchmark.evaluate(X, true_eval=True)\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# none 0\n",
    "# skip_connect 1\n",
    "# nor_conv_1x1 2\n",
    "# nor_conv_3x3 3\n",
    "# avg_pool_3x3 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmaking on NATS search space with objectives: err&params&flops&latency\n",
      "['40:64:8:48:16']\n",
      "[[4 7 0 5 1]] 0 7\n",
      "[[9.27000000e+00 1.94498000e-01 9.67067300e+01 1.55204707e-02]]\n"
     ]
    }
   ],
   "source": [
    "# NATS size search space \n",
    "from evoxbench.benchmarks import NATSBenchmark\n",
    "import numpy as np\n",
    "objs = 'err&params&flops&latency'\n",
    "# ['err&params', 'err&flops', 'err&latency', 'err&params&flops', 'err&params&latency', ...]\n",
    "benchmark = NATSBenchmark(objs=objs, normalized_objectives=False)\n",
    "print(\"Benchmaking on NATS search space with objectives: {}\".format(objs))\n",
    "archs = benchmark.search_space.sample(1)\n",
    "print(archs)\n",
    "X = benchmark.search_space.encode(archs)\n",
    "print(X,np.min(X),np.max(X))\n",
    "F = benchmark.evaluate(X, true_eval=True)\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmaking on DARTS search space with objectives: err&params\n",
      "[[5 0 0 1 0 0 2 2 6 2 0 1 3 2 6 0 4 1 4 0 1 1 5 2 5 2 4 0 6 1 6 3]\n",
      " [3 1 5 0 4 1 3 0 6 0 3 1 3 1 1 0 1 0 5 1 2 1 0 2 0 0 4 2 0 2 5 1]\n",
      " [2 1 4 0 1 2 0 0 0 0 4 3 6 1 3 2 4 0 5 1 0 1 3 2 1 1 2 2 1 2 6 0]\n",
      " [0 0 4 1 5 0 6 2 0 2 1 0 0 3 4 4 0 0 0 1 5 1 0 2 6 1 5 0 3 2 5 1]\n",
      " [1 0 4 1 0 0 3 1 0 3 4 2 0 1 4 3 3 1 0 0 4 0 6 1 1 2 1 0 1 0 6 3]\n",
      " [1 1 5 0 5 0 1 2 6 1 0 2 0 3 4 1 1 1 1 0 2 0 2 1 2 3 6 1 5 4 4 2]\n",
      " [4 1 3 0 1 0 2 2 4 2 6 3 3 4 6 1 2 1 3 0 2 2 0 0 1 2 6 0 1 2 6 4]\n",
      " [0 1 0 0 2 2 6 0 5 3 1 0 5 4 4 1 6 1 5 0 5 1 0 0 4 3 4 2 1 4 6 1]\n",
      " [1 1 6 0 2 1 0 0 2 0 3 3 0 0 6 3 1 0 1 1 6 0 4 1 3 1 6 0 6 4 5 0]\n",
      " [3 1 3 0 3 2 3 0 1 1 1 0 5 4 0 1 6 1 4 0 4 1 3 0 6 1 6 2 3 2 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# DARTS search space\n",
    "from evoxbench.benchmarks import DARTSBenchmark\n",
    "objs = 'err&params'  # ['err&params', 'err&flops', 'err&params&flops']\n",
    "benchmark = DARTSBenchmark(objs=objs, normalized_objectives=False)\n",
    "print(\"Benchmaking on DARTS search space with objectives: {}\".format(objs))\n",
    "archs = benchmark.search_space.sample(10)\n",
    "X = benchmark.search_space.encode(archs)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmaking on DARTS search space with objectives: err&params\n",
      "[Genotype(normal=[('avg_pool_3x3', 1), ('max_pool_3x3', 0), ('skip_connect', 2), ('avg_pool_3x3', 1), ('skip_connect', 3), ('sep_conv_3x3', 2), ('dil_conv_3x3', 1), ('sep_conv_5x5', 3)], normal_concat=[2, 3, 4, 5], reduce=[('sep_conv_3x3', 0), ('sep_conv_3x3', 1), ('avg_pool_3x3', 1), ('sep_conv_5x5', 0), ('sep_conv_3x3', 3), ('dil_conv_3x3', 0), ('sep_conv_5x5', 2), ('dil_conv_5x5', 3)], reduce_concat=[2, 3, 4, 5])]\n",
      "[[1 1 2 0 0 2 1 1 0 3 3 2 5 1 4 3 3 0 3 1 1 1 4 0 3 3 5 0 4 2 6 3]]\n",
      "0.06990354924561082\n"
     ]
    }
   ],
   "source": [
    "# DARTS search space\n",
    "from evoxbench.benchmarks import DARTSBenchmark\n",
    "objs = 'err&params'  # ['err&params', 'err&flops', 'err&params&flops']\n",
    "benchmark = DARTSBenchmark(objs=objs, normalized_objectives=False)\n",
    "print(\"Benchmaking on DARTS search space with objectives: {}\".format(objs))\n",
    "archs = benchmark.search_space.sample(1)\n",
    "print(archs)\n",
    "X = benchmark.search_space.encode(archs)\n",
    "print(X)\n",
    "F = benchmark.evaluate(X, true_eval=True)\n",
    "print(F[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow is not installed.\n",
      "==> Loading performance surrogate model...\n",
      "/opt/data/private/BigFiles/nb_models_1.0/xgb_v1.0\n",
      "[11:17:35] WARNING: ../src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[11:17:37] WARNING: ../src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[11:17:39] WARNING: ../src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[11:17:41] WARNING: ../src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[11:17:43] WARNING: ../src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[11:17:44] WARNING: ../src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[11:17:46] WARNING: ../src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[11:17:48] WARNING: ../src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[11:17:49] WARNING: ../src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[11:17:51] WARNING: ../src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "==> Loading runtime surrogate model...\n",
      "==> Predict runtime and performance...\n",
      "Genotype architecture performance: 92.017384, runtime 4340.575813\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import namedtuple\n",
    "from ConfigSpace.read_and_write import json as cs_json\n",
    "import nasbench301 as nb\n",
    "\n",
    "models_dir = os.path.join('/opt/data/private/BigFiles', 'nb_models_1.0')\n",
    "model_paths = {\n",
    "    model_name : os.path.join(models_dir, '{}_v1.0'.format(model_name))\n",
    "    for model_name in ['xgb', 'gnn_gin', 'lgb_runtime']\n",
    "}\n",
    "print(\"==> Loading performance surrogate model...\")\n",
    "ensemble_dir_performance = model_paths['xgb']\n",
    "print(ensemble_dir_performance)\n",
    "performance_model = nb.load_ensemble(ensemble_dir_performance)\n",
    "\n",
    "# Load the runtime surrogate model\n",
    "#NOTE: Defaults to using the default model download path\n",
    "print(\"==> Loading runtime surrogate model...\")\n",
    "ensemble_dir_runtime = model_paths['lgb_runtime']\n",
    "runtime_model = nb.load_ensemble(ensemble_dir_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Predict runtime and performance...\n",
      "Genotype architecture performance: 93.472656, runtime 5595.149626\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "print(\"==> Predict runtime and performance...\")\n",
    "prediction_genotype = performance_model.predict(config=archs[0], representation=\"genotype\", with_noise=False)\n",
    "runtime_genotype = runtime_model.predict(config=archs[0], representation=\"genotype\")\n",
    "print(\"Genotype architecture performance: %f, runtime %f\" %(prediction_genotype, runtime_genotype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmaking on ResNet50D search space with objectives: err&params&flops\n",
      "[{'r': 128, 'w': [1, 2, 0, 0, 0, 1], 'e': [0.25, 0.35, 0.25, 0.35, 0.35, 0.25, 0.35, 0.25, 0.25, 0.25, 0.25, 0.2, 0.25, 0.2, 0.2, 0.2, 0.35, 0.2], 'd': [0, 2, 1, 2, 2]}]\n",
      "[[0 0 0 1 1 1 2 2 3 2 3 3 2 3 0 2 2 2 1 2 1 1 1 3 1]]\n",
      "[[2.71153254e-01 1.69836400e+07 1.54778869e+09]]\n"
     ]
    }
   ],
   "source": [
    "# ResNet50D search space \n",
    "from evoxbench.benchmarks import ResNet50DBenchmark\n",
    "objs = 'err&params&flops'\n",
    "# ['err&params', 'err&flops', 'err&params&flops']\n",
    "benchmark = ResNet50DBenchmark(objs=objs, normalized_objectives=False)\n",
    "print(\"Benchmaking on ResNet50D search space with objectives: {}\".format(objs))\n",
    "archs = benchmark.search_space.sample(1)\n",
    "print(archs)\n",
    "X = benchmark.search_space.encode(archs)\n",
    "print(X)\n",
    "F = benchmark.evaluate(X, true_eval=True)\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmaking on Transformer search space with objectives: err&params&flops\n",
      "[{'depth': 15, 'embed_dim': 624, 'mlp_ratio': [4.0, 3.0, 4.0, 3.5, 3.0, 3.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.5, 3.5, 3.5, 3.5], 'num_heads': [9, 10, 10, 9, 9, 10, 10, 10, 9, 9, 9, 10, 10, 9, 10]}]\n",
      "[[1 2 2 0 2 1 0 0 2 2 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 0 1 1 0 1 0]]\n",
      "[[1.81047950e-01 6.44097280e+07 1.34198077e+10]]\n"
     ]
    }
   ],
   "source": [
    "# Transformer search space \n",
    "from evoxbench.benchmarks import TransformerBenchmark\n",
    "objs = 'err&params&flops'\n",
    "# ['err&params', 'err&flops', 'err&params&flops']\n",
    "benchmark = TransformerBenchmark(objs=objs, normalized_objectives=False)\n",
    "print(\"Benchmaking on Transformer search space with objectives: {}\".format(objs))\n",
    "archs = benchmark.search_space.sample(1)\n",
    "print(archs)\n",
    "X = benchmark.search_space.encode(archs)\n",
    "print(X)\n",
    "F = benchmark.evaluate(X, true_eval=True)\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmaking on MobileNetV3 search space with objectives: err&params&flops\n",
      "[{'r': 192, 'ks': [7, 7, 5, 7, 3, 7, 3, 5, 3, 7, 5, 5, 3, 3, 5, 7, 7, 3, 3, 5], 'e': [3, 6, 6, 3, 6, 3, 6, 3, 6, 4, 4, 4, 3, 6, 3, 3, 3, 3, 4, 3], 'd': [4, 4, 3, 4, 4]}]\n",
      "[[2 3 9 8 3 7 3 7 2 7 6 5 0 1 7 2 3 3 1 4 2]]\n",
      "[[2.30890867e-01 6.74452000e+06 7.89135696e+08]]\n"
     ]
    }
   ],
   "source": [
    "# MobileNetV3 search space \n",
    "from evoxbench.benchmarks import MobileNetV3Benchmark\n",
    "objs = 'err&params&flops'\n",
    "# ['err&params', 'err&flops', 'err&latency', 'err&params&flops', 'err&params&latency', ...]\n",
    "benchmark = MobileNetV3Benchmark(objs=objs, normalized_objectives=False)\n",
    "print(\"Benchmaking on MobileNetV3 search space with objectives: {}\".format(objs))\n",
    "archs = benchmark.search_space.sample(1)\n",
    "print(archs)\n",
    "X = benchmark.search_space.encode(archs)\n",
    "print(X)\n",
    "F = benchmark.evaluate(X, true_eval=True)\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
